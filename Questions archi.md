Architecture Data Mesh avec Azure Databricks, Microsoft Fabric (OneLake) et Purview

Show more lines
1. Séparation logique des Data Domains
Choix de l’isolation : Dans une architecture data mesh, il est crucial de définir des périmètres clairs pour chaque domaine de données (domaine métier). La question est de savoir comment traduire ces domaines dans Azure : isolés par souscriptions distinctes ou simplement par Resource Groups au sein d’une même souscription, voire d’autres découpages.
Recommandation : Il est fortement recommandé de séparer chaque domaine de données dans sa propre souscription Azure plutôt que de regrouper plusieurs domaines dans un même abonnement. Microsoft préconise cette approche dans l’architecture Cloud-Scale Analytics pour les déploiements à grande échelle. En pratique, une souscription = un domaine apporte plusieurs bénéfices : [learn.microsoft.com]

Facturation claire par domaine : La souscription est l’unité de facturation native sur Azure. En dédiant une souscription par domaine, on obtient automatiquement un découpage des coûts par entité métier sans effort supplémentaire. Chaque domaine peut se voir attribuer un budget et suivre sa consommation de manière séparée. Exemple : Si le domaine Marketing est une souscription distincte, on peut extraire son coût mensuel exact, facilitant le showback/chargeback. Sur une seule souscription partagée, il faudrait recourir aux tags ou des calculs pour estimer la part de chaque domaine, ce qui est plus complexe et potentiellement moins précis. [learn.microsoft.com]
Isolation des quotas et des ressources : Les quotas Azure (ex. nombre de vCPU, limites de services) s’appliquent par souscription. En cloisonnant les domaines, on évite qu’un domaine consomme les ressources au détriment des autres. Chaque domaine peut évoluer jusqu’aux limites de sa souscription sans impacter les autres. Au contraire, une souscription unique partagée s’expose au risque de saturer un quota global (par ex. trop de VMs déployées par un domaine empêchant un autre de démarrer un cluster). Microsoft souligne que l’absence de découpage par souscription peut freiner l’adoption une fois certaines limites atteintes. [learn.microsoft.com]
Gouvernance et sécurité adaptées : Une souscription offre un périmètre d’administration et de sécurité. On peut attribuer les rôles Azure (Owner, Contributor, Reader) uniquement à l’équipe du domaine sur sa souscription, sans qu’elle n’ait de visibilité sur les ressources des autres domaines. De même, on peut appliquer des politiques (Azure Policy) spécifiques par souscription pour adapter les règles de conformité à chaque entité. Par exemple, le domaine Finance pourrait avoir des politiques plus strictes (chiffrement CMK, région spécifique) sans imposer ces contraintes aux domaines moins sensibles. Dans une souscription partagée, les rôles d’administration et les policies sont communs, au risque qu’un administrateur d’un domaine ait des privilèges sur l’ensemble ou qu’une policy trop générale bride inutilement certains usages. [learn.microsoft.com]
Autonomie des équipes et découpage organisationnel : Ce modèle reflète l’organisation interne de l’entreprise. Si chaque division métier gère son propre domaine de données, lui confier une souscription dédiée lui donne l’autonomie pour innover à son rythme, tout en restant dans un cadre contrôlé. Par exemple, l’équipe du domaine Supply Chain peut administrer sa souscription (déployer de nouvelles ressources, ajuster sa capacité) sans affecter les autres domaines, à condition de respecter les gardes-fous globaux. Cette indépendance évite les goulets d’étranglement d’une équipe centralisée unique. On retrouve ici le principe “data as a product” du data mesh : chaque domaine gère son produit de données de bout en bout, ce qui est facilité s’il maîtrise aussi son infrastructure cloud (dans les limites fixées par la DSI). [learn.microsoft.com]

En synthèse, segmenter par souscriptions permet de mieux respecter les frontières des domaines tant du point de vue financier que technique. C’est une approche plébiscitée pour les grandes organisations avec de nombreux domaines, car elle apporte une capacité de passage à l’échelle en ajoutant des souscriptions à mesure que de nouveaux domaines apparaissent. D’ailleurs, Azure utilise la souscription comme unité de scale horizontale : en cas de besoins accrus, on peut ajouter un nouvel abonnement (ou en partitionner un existant) pour répartir la charge, ce qui offre une réserve de croissance quasiment illimitée en multipliant les abonnements. [learn.microsoft.com]
Alternative (non préférée) – Plusieurs domaines dans une même souscription : Il serait possible de créer un seul abonnement Azure englobant les 20 entités, en distinguant les domaines par des Resource Groups, des naming conventions ou des tags. Cette approche peut convenir pour un petit nombre de domaines très liés, mais elle présente des inconvénients qui la rendent peu viable à l’échelle de 20 entités :

Show more lines
En effet, dans une souscription unique, la gestion centralisée devient complexe : il faut distinguer les ressources de chaque domaine via des conventions (préfixes, tags) pour les repérer, et filtrer les rapports de consommation par tags pour estimer le coût par domaine. Surtout, on perd l’étanchéité entre domaines : un utilisateur ayant besoin de droits élevés pour le domaine A obtiendrait souvent ces droits au niveau de la souscription et pourrait donc affecter le domaine B. Azure le souligne : accorder des privilèges élevés à un utilisateur dans une souscription multi-domaines lui donne implicitement des privilèges sur tous les domaines de cet abonnement – à l’opposé du principe de moindre privilège. De plus, les limites d’abonnement finissent par frapper l’ensemble de l’organisation : une seule subscription concentre toutes les charges, et même si Azure permet d’augmenter certains quotas sur demande, ce n’est pas infini et cela peut devenir un frein à l’adoption cloud. [learn.microsoft.com]
Enfin, du point de vue opérationnel, une souscription partagée complexifie le dépannage et l’évolution : difficile de tester une nouvelle politique ou un nouveau service pour un domaine sans impacter potentiellement les autres (alors qu’avec des souscriptions séparées, on peut par exemple activer une préversion de service uniquement sur la souscription du domaine pilote sans risque pour les autres).
Conclusion : Au vu de ces éléments, la séparation par souscriptions apparaît comme la meilleure option pour un data mesh multi-entités. Chaque domaine (sur ses 20 entités) disposera de son abonnement, garantissant une isolation forte des responsabilités, des coûts et des ressources. Cela n’empêche pas une gestion centralisée là où c’est nécessaire (via des outils multi-abonnements que nous aborderons), mais cela fournit une base saine pour faire croître l’architecture de manière modulaire. Des entreprises ayant adopté Azure pour un data mesh confirment ce choix : par exemple, une grande banque a attribué une subscription par direction métier et utilise des Management Groups Azure pour regrouper ces abonnements et appliquer des règles communes globales (log standardisé, tagging obligatoire, etc.), tout en laissant chaque équipe métier propriétaire de son espace. Cette stratégie a permis de passer à l’échelle facilement en ajoutant de nouvelles souscriptions à mesure que de nouveaux domaines de données apparaissaient, sans refonte majeure de l’existant.
2. Limites de l’approche par souscription et migration des ressources existantes
Si l’on opte pour la séparation par souscriptions (solution privilégiée), il convient d’anticiper les contraintes associées et de planifier la migration de l’état actuel vers cette nouvelle organisation.
2.1 Contraintes et considérations du multi-souscriptions

Nombre d’abonnements à gérer : Avec 20 domaines, on aura 20 souscriptions (sans compter les environnements de Dev/Test, cf. section 6). Azure permet d’en gérer autant que nécessaire, mais il faudra s’organiser. L’utilisation des Management Groups Azure est utile pour structurer ces souscriptions (par ex., un groupe parent "DataMesh" englobant les 20 souscriptions) et appliquer des réglages globalement. Il est essentiel d’automatiser le déploiement des ressources communes dans chaque abonnement pour éviter une gestion manuelle fastidieuse. On peut recourir à des scripts (Azure CLI, PowerShell) ou à de l’IaC (Terraform, Bicep) pour créer les ressources de base de chaque domaine de façon cohérente. Par exemple, un pipeline CI/CD pourrait déployer le même template de landing zone (stockage, analytics, réseau...) sur chaque souscription de domaine.
Connectivité réseau inter-domaines : Par défaut, les ressources de deux souscriptions distinctes ne communiquent pas directement sur le réseau virtuel. Si des flux de données doivent transiter entre domaines, il faudra mettre en place des peering entre les Virtual Networks de leurs landing zones, ou utiliser des services d’intégration (Service Bus, API Management) accessibles via internet ou via des Private Endpoints. Cela ajoute un peu de complexité réseau (gestion des pairs, DNS, etc.). Heureusement, dans un data mesh, on favorise le partage via des couches d’API ou de données publiées (comme OneLake) plutôt que via un accès direct au stockage d’un autre domaine. Les besoins de connectivité directe restent donc limités (typiquement, pour qu’un pipeline d’un domaine A appelle un service dans le domaine B, ou si plusieurs domaines partagent un référentiel commun). Azure recommande un hub réseau central (Shared VNet ou hub-and-spoke) ou un maillage (mesh) pour connecter les landing zones analytiques de manière sécurisée. Chaque VNet de domaine peut être peeré au hub de manière à ce que, si nécessaire, les échanges inter-domaines passent par ce hub sécurisé. [learn.microsoft.com]
Visibilité et gouvernance centralisées : Avec 20 abonnements, la vue d’ensemble nécessite des outils centralisateurs. Azure propose par exemple Azure Monitor (Log Analytics) pour agréger les logs et métriques de tous les domaines dans un workspace central, ou Azure Cost Management (via un Management Group) pour suivre les dépenses globales. De même, Microsoft Purview (voir section 7) jouera le rôle de catalogue transversal. La DSI devra configurer ces outils globaux, mais une fois en place, on bénéficie du meilleur des deux mondes : une gouvernance globale cohérente et des équipes locales autonomes.
Gestion des identités sur plusieurs souscriptions : On évitera d’assigner individuellement les utilisateurs sur chaque souscription. À la place, on définira des Groupes Azure AD correspondants aux rôles souhaités et on les assignera dans les abonnements. Par exemple, un groupe “DataDomain_Finance_Admins” aura le rôle Owner sur la souscription du domaine Finance, un groupe “DataDomain_Finance_Users” le rôle Lecteur, etc. Ainsi, l’arrivée ou le départ d’une personne se gère en modifiant son appartenance au groupe adéquat, répliquée sur toutes les ressources du domaine.
Mutualisation de services : Certaines ressources analytiques ne se partagent pas aisément entre souscriptions. Par exemple, un même cluster Azure Databricks ne peut pas appartenir à deux subscriptions : chaque workspace Databricks est lié à un abonnement unique. Dans notre cas, ce n’est pas un problème, au contraire, nous souhaitons un workspace par domaine. Il faudra juste prévoir une instance Databricks par domaine. Idem pour les comptes de stockage : chaque domaine aura le sien, plutôt qu’un stockage commun (et si un stockage doit être commun pour un usage transverse, on peut le placer dans la souscription Data Management centrale, ou le répliquer). Microsoft Purview, lui, est pensé pour couvrir l’ensemble : on déploiera un compte Purview central (dans une souscription dédiée à la gouvernance, par exemple) qui ira scanner les données dans toutes les souscriptions domaines. En résumé, peu de services seront mutualisés entre domaines – ce qui est cohérent avec l’esprit du data mesh.

En contrepartie de ces quelques contraintes, l’approche multi-souscriptions apporte une scalabilité et une compartimentation supérieures. Et les outils Azure modernes sont conçus pour la gestion multi-abonnements, atténuant significativement la charge d’administration centralisée.
2.2 Migration des ressources vers la nouvelle architecture
Le client dispose actuellement d’une plateforme Databricks + Power BI pour l’une de ses entités (sans doute déployée dans une souscription unique ou partagée). Étendre l’architecture à 20 entités via Fabric/OneLake impliquera de restructurer les ressources Azure en conséquence. Les principales opérations de migration seront :


Migrer le stockage de données (Data Lake) : S’il existe un compte de stockage ADLS Gen2 contenant les données de l’entité actuelle, on voudra le rattacher à la nouvelle souscription du domaine correspondant. Azure permet de déplacer un compte de stockage d’une souscription à une autre (au sein du même tenant Azure AD). Cette opération se fait via Azure Resource Manager (Portal, CLI ou PowerShell). Pendant le déplacement, le compte de stockage est verrouillé au niveau management (on ne peut pas changer sa configuration), mais les données restent accessibles en lecture/écriture pendant la migration. Le déplacement d’un stockage de 10 To par exemple est possible sans interrompre les applications clientes. En cas d’échec du move, l’abonnement source n’est pas modifié, le compte reste en place. En pratique : on sélectionne le resource group du stockage, on choisit Move to another subscription, on valide. Il faut s’assurer que toutes les ressources dépendantes suivent (le plus simple est de mettre le compte de stockage dans un RG qui ne contient rien d’autre d’indispensable, ou de déplacer tout le RG). Après l’opération, les ID de ressource Azure du stockage auront changé (nouvel ID de souscription dans l’URI), il faudra donc vérifier les références (par ex. les montages Databricks, les clés stockées dans des Key Vault, etc., et mettre à jour l’ID si nécessaire). [learn.microsoft.com]
Remarque : Le move ARM est supporté pour les comptes de stockage. Certaines ressources plus complexes comme Azure Synapse Analytics Workspace ou Azure ML Workspace ne supportent pas le move et nécessitent une recréation, mais un compte de stockage standard se déplace très bien. [learn.microsoft.com]
Une alternative si le move direct était impossible (par exemple, entre deux tenants différents, ou si on préférait ne pas toucher à l’existant) consisterait à copier les données vers un nouveau compte de stockage déployé dans la nouvelle souscription, via AzCopy, Data Factory ou synapse pipeline. Mais ce n’est pas nécessaire ici puisque tout reste dans le même tenant.


Migrer Azure Databricks : Un workspace Azure Databricks existant ne peut pas être déplacé vers une autre souscription. Azure Resource Manager ne supporte pas le move de cette ressource (comme confirmé par Microsoft). Dès lors, la stratégie est de déployer un nouveau workspace Databricks sur la souscription cible et d’y migrer le contenu depuis l’ancien workspace. Cela inclut les notebooks, les jobs, les configurations et éventuellement les tables de données. [learn.microsoft.com]
Microsoft fournit des outils pour faciliter cette migration logique :

Le projet open-source Databricks Labs – Migrate sur GitHub permet l’export/import en masse des assets d’un workspace (notebooks, clusters, jobs, etc.). [learn.microsoft.com]
On peut aussi utiliser directement le Databricks CLI et les API REST pour scripter l’export puis l’import.

Étapes typiques :

Exporter les notebooks et configurations du workspace source. Par exemple, avec le CLI Databricks : databricks workspace export_dir / /tmp/export_all va exporter tous les dossiers et notebooks de la racine vers un répertoire local. On peut de même exporter la liste des jobs (API 2.0/jobs) et les configurations de clusters (API 2.0/clusters).
Créer le nouveau workspace Databricks dans la nouvelle souscription (via le portail Azure ou IaC). L’option SKU Premium est conseillée (pour Unity Catalog). Configurer les paramètres de réseau et sécurité désirés (par ex. activer No Public IP si on veut forcer le privé).
Importer les notebooks dans le nouveau workspace : databricks workspace import_dir /tmp/export_all /. Recréer les dossiers de librairies si nécessaire, et réimporter les définitions de jobs à partir des exports JSON effectués.
Reconnecter les données : si les tables Delta de l’ancien workspace pointaient vers un stockage ADLS externe (ce qui est courant), et que ce stockage a été déplacé ou recréé comme indiqué plus haut, il suffit de rattacher ce stockage au nouveau workspace (montage DBFS ou configuration d’une External Location via Unity Catalog). Ainsi, les tables pourront être recréées en pointant vers les mêmes fichiers parquet/delta. Si l’ancien workspace utilisait le stockage géré (DBFS root) pour stocker des tables, il faudra extraire ces données (par ex. en les copiant sur ADLS ou via un export).
Vérifier et ajuster : recréer les clusters dans le nouveau workspace avec les mêmes caractéristiques (versions de runtime, librairies installées, propriétés). Relancer quelques notebooks critiques pour s’assurer que tout fonctionne.

Une fois le nouveau workspace prêt, on peut basculer la charge dessus et éteindre (ou supprimer) l’ancien. Cette migration peut être planifiée de manière à minimiser l’indisponibilité : par exemple, on arrête les mises à jour sur l’ancien le temps d’exporter définitivement les dernières modifs, puis on redémarre sur le nouveau – typiquement une coupure de quelques heures suffit pour un passage de relais propre, voire moins si bien préparé.
Exemple de script CLI pour migrer les notebooks :


HTML# Sur le workspace source (export de tout le contenu)databricks workspace export_dir / /tmp/export_domaineA# Sur le workspace cible (import de tout le contenu)databricks workspace import_dir /tmp/export_domaineA /Show more lines
Il s’agit d’un exemple simplifié ; dans la pratique on filtrerait possiblement par dossier (ex: /Shared) et on scripterait aussi l’import des jobs (via databricks jobs create avec les JSON exportés).

Migrer les tableaux de bord Power BI : Power BI étant un service SaaS rattaché à un tenant Office 365, il n’y a pas de notion de souscription Azure pour les rapports. Les rapports existants continueront de fonctionner, mais il faudra repointer leurs sources de données. Autrement dit, si un dataset Power BI se connectait au cluster Databricks ancien ou à un stockage, on devra lui indiquer la nouvelle source (par exemple, le nouvel endpoint OneLake ou le nouveau cluster Databricks). C’est l’occasion d’adopter les nouvelles connexions Fabric (DirectLake, etc.) pour améliorer les performances (voir section 4).

En résumé, la migration consiste surtout à reloger les données (déplacement du Data Lake) et basculer l’outil de transformation (Databricks) vers des instances par domaine. Cette transition peut se faire domaine par domaine pour étaler la charge : on pourrait commencer par migrer l’entité existante vers le nouveau modèle (domaine pilote), puis on-boarder les nouvelles entités l’une après l’autre en leur créant leur souscription, en déployant les ressources (stockage, Databricks, etc.), puis en important leurs données.
Azure fournit un guide et des checklists pour les moves de ressources et de nombreux clients ont réalisé ce genre de scission d’une plateforme centralisée en plusieurs sous-environnements – l’important est de bien tester le plan sur une petite volumétrie avant de l’exécuter en production. [learn.microsoft.com]
3. Organisation d’un Data Domain et lien avec OneLake
Chaque domaine de données correspond à une équipe et un périmètre métier responsables de certaines données de l’entreprise. Concrètement, dans Azure, un domaine va regrouper un ensemble de ressources pour ingérer, stocker, transformer et exposer ses données.
3.1 Structure interne d’un domaine de données
Ressources principales d’un domaine :

Un ou plusieurs sources de données brutes à ingérer (bases transactionnelles, fichiers plats, API, etc.). L’ingestion peut être réalisée via Azure Data Factory/Synapse Pipeline, ou via Databricks lui-même (par exemple en streaming ou using Databricks Autoloader).
Un compte de stockage Azure (Blob Storage/ADLS Gen2) faisant office de Data Lake du domaine. On y organise en général plusieurs conteneurs correspondant aux différentes zones de données : souvent, Bronze (raw, données brutes), Silver (données nettoyées/normalisées), Gold (données prêtes à l’usage, agrégées ou enrichies). Ce modèle en couches, inspiré de Delta Lake, est courant et il est pris en charge par l’architecture Cloud-Scale Analytics de Microsoft (qui parle de Raw/Enriched/Curated, où Curated = Gold, la couche « produit » pour la consommation). [learn.microsoft.com]
Un workspace Azure Databricks dédié, pour ce domaine. C’est la plateforme de calcul utilisée par les data engineers/scientists du domaine pour développer des notebooks, des jobs planifiés, faire du machine learning, etc. Databricks va puiser dans le Data Lake du domaine pour lire les données brutes et écrire les données transformées. On configurera le workspace pour qu’il accède à son compte de stockage (via montages DBFS, accès direct ou External locations Unity Catalog).
Unity Catalog (métastore unifié de Databricks) configuré sur ce workspace. Unity Catalog permet de créer des catalogues de données, schémas et tables Delta partagés au sein du domaine, avec un contrôle d’accès centralisé. Par exemple, le domaine X peut avoir un catalogue nommé domaineX, avec des schémas bronze, silver, gold contenant les tables correspondantes. Unity Catalog stocke les métadonnées (schémas, ACLs) et gère le partage potentiel de ces données (voir section 5).
Un ensemble de Data Products : ce sont les objets de données que le domaine met à disposition pour les autres (ou pour la consommation finale). Ce sont typiquement des tables Gold particulièrement utiles, des vues agrégées, ou encore des features ML, etc. Par exemple, le domaine Ventes pourrait avoir un data product « Ventes mensuelles par région ». Techniquement, à ce stade, il s’agit peut-être d’une table Delta dans le schéma Gold du domaine, ou d’une vue dans Databricks. L’important est qu’elle soit clairement identifiée et gouvernée (avec description, SLA de mise à jour, responsable identifié… idéalement via Purview).

Exposition des Data Products : C’est ici qu’intervient Microsoft Fabric OneLake dans notre architecture. OneLake va servir de couche d’exposition unifiée pour tous les domaines, c’est-à-dire la vitrine où chaque domaine publie ses data products pour les rendre facilement accessibles aux consommateurs.
OneLake est le data lake unifié de Microsoft Fabric. On peut le voir comme un « méga-lac » virtuel englobant les données analytiques de l’organisation, ou comme une abstraction fédérée au-dessus des lacs de chaque domaine. L’idée clé est de centraliser l’accès sans centraliser physiquement les données.
3.2 Connexion d’un domaine à OneLake
Comment un domaine « publie »-t-il ses données dans OneLake ? Deux méthodes principales (complémentaires) existent dans Fabric pour intégrer des données existantes :


Via des Shortcuts OneLake : Le service OneLake permet de créer des raccourcis (pointeurs) vers des sources de données externes (un peu à la manière d’un lien symbolique). Concrètement, depuis un Lakehouse Fabric (un entrepôt de fichiers géré par Fabric dans OneLake), on peut ajouter un raccourci pointant vers un conteneur ADLS Gen2 du domaine. Par exemple, le domaine X a un conteneur domaineX-gold sur son stockage ; on crée dans Fabric un Lakehouse « DomaineX » puis on ajoute un raccourci vers abfss://domaineX-gold@monstorage.dfs.core.windows.net/. Ainsi, OneLake « monte » ce conteneur comme s’il faisait partie de OneLake. Aucune copie n’est effectuée : les fichiers restent dans la souscription du domaine, mais OneLake les voit et y accède en direct. L’avantage est évident : on évite la duplication des données, les coûts supplémentaires et les problèmes de synchronisation. Les utilisateurs de Fabric pourront lire ces données via le Lakehouse, et ce sont bien les données à jour du domaine qui seront derrière. Ce mécanisme de shortcut est un élément central de Fabric OneLake pour la fédération de lacs. [databricks.com], [techcommun...rosoft.com]


Via le mirroring Unity Catalog : Microsoft Fabric offre une fonctionnalité d’Azure Databricks mirroring. Il s’agit de connecter Fabric à un workspace Databricks et son Unity Catalog, de manière à répliquer les métadonnées des tables dans Fabric. Quand on met en place ce mirroring, on crée dans Fabric un élément de type “Mirrored Azure Databricks Catalog” en choisissant quel catalog (et schémas) on veut exposer. Fabric va alors lister toutes les tables de ce catalog et créer pour chacune un shortcut automatique dans OneLake. Du point de vue de l’utilisateur Fabric, ça apparaît comme une base de données (un entrepôt SQL) contenant des tables, mais en réalité les données de ces tables sont toujours stockées dans le Data Lake du domaine et accessibles via OneLake. Le mirroring est en quelque sorte une surcouche par-dessus les shortcuts : il apporte la découverte des tables (avec leurs schémas) directement dans l’interface Fabric, sans avoir à manuellement créer chaque raccourci de dossier. Techniquement, Fabric interroge Unity Catalog via des API ouvertes pour obtenir la liste des tables, puis crée des liens OneLake vers les fichiers Delta correspondants. Cette solution est très puissante car elle permet par exemple à un analyste d’utiliser du SQL natif dans Fabric (via un endpoint SQL) pour interroger les tables du domaine sans avoir à se soucier d’où elles sont stockées physiquement – le tout sans déplacer de données. [blog.fabri...rosoft.com]


Ces deux approches peuvent coexister. On peut imaginer qu’un domaine expose la plupart de ses data products via le mirroring (toutes les tables Gold apparaissent dans Fabric), mais utilise en plus un Lakehouse Fabric pour, par exemple, déposer quelques fichiers CSV de référence. L’important est que OneLake devienne le point d’entrée unique pour consommer les données, même si celles-ci restent distribuées dans les souscriptions.
Architecture d’un domaine avec OneLake : Visualisons comment un domaine s’intègre à OneLake :
Show more lines
Schéma : Le domaine utilise son workspace Databricks pour alimenter son Data Lake interne (fichiers Parquet/Delta en bronze, silver, gold). Plutôt que de copier ces données dans un lac central, on crée un raccourci OneLake vers le conteneur Gold du domaine. Ainsi, OneLake référence directement les fichiers du domaine (trait gris continu). Les consommateurs (utilisateurs Power BI, Data Scientists, etc.) peuvent accéder aux données via Fabric OneLake – par exemple, un rapport Power BI peut se connecter au Lakehouse du domaine en mode DirectLake (lecture directe des fichiers parquet) ou un data scientist peut interroger les tables via le point SQL du Lakehouse – sans que les données n’aient été dupliquées.
En option (non illustré dans ce schéma simplifié), on pourrait activer le mirroring Unity Catalog : dans ce cas, Fabric créerait en plus un élément SQL (entreprise de données) représentant les tables du domaine, permettant un accès SQL direct. Que l’on passe par le Lakehouse ou le mirror SQL, c’est en fait OneLake qui sert les données en allant les lire dans le Data Lake du domaine.
3.3 Consommation et utilisation des data products
Grâce à cette architecture, lorsqu’un domaine produit une nouvelle donnée de valeur (disons une table Gold “Ventes_Annuelles”), voici ce qui se passe : la table est enregistrée dans Databricks (schéma Gold du domaine) et les fichiers correspondants sont écrits sur le stockage du domaine. Presque immédiatement, cette table apparaît dans Fabric OneLake : soit parce que le Lakehouse du domaine a un raccourci général sur tout le dossier Gold (donc les fichiers sont visibles), soit via le catalog mirror qui la liste. Un utilisateur de Power BI peut alors la trouver dans le hub de données Fabric, sans avoir besoin de connaître l’existence du workspace Databricks.
Ce mode de fonctionnement présente plusieurs avantages majeurs :

On maintient une architecture distribuée (chaque domaine garde la propriété de ses données dans sa souscription), tout en offrant une expérience unifiée aux utilisateurs finaux (toutes les données sont visibles via OneLake/Purview).
On évite la création de silos isolés : si un domaine souhaite utiliser une donnée d’un autre domaine, il peut le faire via OneLake en créant un raccourci vers le Lakehouse partagé de l’autre ou via Purview pour la découvrir, au lieu de demander une extraction manuelle. Par exemple, le domaine Marketing peut créer un shortcut vers la table “Ventes_Annuelles” du domaine Ventes (si elle lui a été partagée), afin de l’utiliser dans ses propres analyses – le tout sans doublon, en lisant sur la source unique du domaine Ventes. [techcommun...rosoft.com]
On bénéficie de la puissance des moteurs Fabric (comme le moteur DirectLake pour Power BI, ultra performant, ou les notebooks Spark de Fabric si on en a besoin) en conjonction de la puissance de Databricks, sans opposer les deux. Les données format Delta peuvent être exploitées simultanément des deux côtés.
La synchronisation est naturelle : puisqu’il n’y a pas de copie, la question de “quand mes données du lac central seront à jour par rapport à Databricks” ne se pose pas. Databricks et Fabric travaillent sur les mêmes fichiers. À chaque rafraîchissement, les consommateurs voient instantanément les nouvelles données.

Remarque : OneLake introduit le concept de Domaines Fabric (à ne pas confondre avec les domaines de données conceptuels). On peut associer des workspaces Fabric à des domaines Fabric pour regrouper les artefacts par domaine métier. Par exemple, on pourrait créer un domaine Fabric “Ventes” et y placer le workspace Lakehouse “Ventes”. Cela sert surtout à la gouvernance dans Fabric (délégation de l’administration du workspace aux owners du domaine, etc.). C’est une fonctionnalité supplémentaire de Fabric facilitant l’organisation, mais qui n’est pas obligatoire pour notre architecture – c’est une couche d’organisation logique au sein de Fabric. [techcommun...rosoft.com], [techcommun...rosoft.com]
4. Intégration technique entre Databricks et OneLake (Fabric)
Approfondissons le fonctionnement technique de cette intégration hybride Databricks–Fabric, car elle est au cœur de la solution.
L’objectif est que les données préparées dans Azure Databricks (stockées en Delta Lake sur ADLS) soient consultables à travers Microsoft Fabric OneLake, par différents moteurs (Power BI, SQL, etc.), sans réplication.
Voici comment cela s’opère :

Show more lines
On peut ainsi consulter les mêmes données de deux façons dans Fabric :

Mode “Lakehouse” (via Spark/DirectLake) : Par exemple, un data analyst peut se connecter au Lakehouse du domaine Ventes depuis Power BI en mode DirectLake. Dans ce mode, Power BI lit directement les fichiers parquet du Lakehouse, donc ceux du domaine, sans passer par un moteur SQL. C’est très efficace pour des tableaux de bord car on évite la latence d’une requête SQL live – les données sont chargées en mémoire de façon optimisée.
Mode “Entrepôt SQL” (via Mirror) : Un utilisateur peut aussi se connecter à l’entrepôt SQL Fabric (créé par le mirror du catalog Ventes). Là, il voit des tables et peut faire des requêtes SQL. Quand il en exécute une, Fabric va soit pousser la requête vers un moteur Spark derrière (technique du query pushdown) soit accéder aux fichiers via son propre moteur SQL, mais dans les deux cas en lisant les données du domaine. Ce mode est pratique pour des besoins d’exploration ad hoc ou d’intégration avec des outils qui parlent SQL.

Ces deux modes ne doublonnent pas les données – ils fournissent deux voies d’accès. Fabric stocke simplement les métadonnées et quelques caches éventuellement, mais pas les tables elles-mêmes (sauf si on choisit de matérialiser quelque chose).
Le schéma suivant illustre l’architecture d’intégration pour un domaine donné, avec les deux voies de consommation :
Show more lines
Schéma : Azure Databricks (DBX) du domaine X stocke ses tables dans ADLS. Fabric OneLake intègre ce stockage via un shortcut dans un Lakehouse (LH) du domaine X. Parallèlement, Fabric se connecte à Unity Catalog (UC) du Databricks pour créer un SQL Endpoint miroir des tables. L’utilisateur (User) peut soit accéder aux données par le Lakehouse (flèche de gauche), soit via le SQL Endpoint (flèche de droite). Dans les deux cas, il n’y a pas de copie des données : le Lakehouse et le Endpoint renvoient vers ADLS ou passent par l’API d’Unity Catalog sur Databricks.
Quelques points techniques supplémentaires méritent d’être soulignés :

Performances de lecture : OneLake utilise le format de stockage natif (Delta/Parquet) qui est colonnaire et compressé, ce qui est optimal pour les requêtes analytiques. En mode DirectLake, Power BI peut atteindre des performances quasi-équivalentes à un import en mémoire, car il lit directement des pages de colonnes dans les fichiers parquet. De plus, Fabric utilise des caches intelligents : si une table est souvent accédée, il peut en conserver certaines parties en cache dans le service pour accélérer les prochaines lectures. Côté Databricks, le fait d’utiliser Delta Lake assure aussi une efficacité maximale (index, statistiques) lors des mises à jour ou relectures.
Synchronisation des métadonnées : Lorsque de nouvelles tables sont ajoutées dans Unity Catalog ou que le schéma change, Fabric le détecte (selon un intervalle ou via actualisation manuelle) et met à jour ses objets mirror. Il peut y avoir un léger délai (de l’ordre de la minute) pour que Fabric reflète un tout nouveau schéma, mais c’est bien plus rapide que d’avoir à créer un pipeline d’ETL pour synchroniser deux systèmes. [blog.fabri...rosoft.com]
Interopérabilité future : À fin 2025, Microsoft et Databricks ont annoncé le travail sur la possibilité pour Databricks de lire directement OneLake, grâce à l’adoption d’API ouvertes communes. Cela signifie qu’à terme, l’intégration sera bidirectionnelle : not only Fabric peut voir les données Databricks, mais Databricks pourra voir des données Fabric. Dans notre cas, ce n’est pas spécialement nécessaire (car les sources de vérité sont dans Databricks), mais si un jour un domaine stocke certaines données seulement dans OneLake, Databricks pourra y accéder sans mouvement de données. Cette évolution s’inscrit dans une tendance d’interopérabilité accrue entre plateformes d’analyse, bénéfique pour éviter tout enferment propriétaire. [databricks.com], [databricks.com]

En pratique, l’intégration Databricks–OneLake que nous avons mise en place est un exemple de ce qu’on appelle parfois un “multi-engine architecture” : on utilise plusieurs moteurs analytiques (Spark Databricks, Fabric engine, Power BI) sur un lakehouse de données partagé. Le tout est rendu possible grâce à Delta/Parquet (formats ouverts) et aux nouvelles API de catalogues unifiés. On obtient ainsi un système très flexible : les équipes data n’ont pas à choisir entre Databricks ou Fabric, elles peuvent tirer parti des deux où ils excellent (Databricks pour le data processing lourd ou le machine learning, Fabric pour l’analyse BI temps réel, etc.), sans créer deux silos distincts.
5. Gestion des droits et sécurité dans l’architecture hybride
La sécurité des données est un aspect crucial, surtout dans une architecture où cohabitent Databricks (Unity Catalog) et Fabric (OneLake). Le client utilise déjà Unity Catalog pour gouverner l’accès aux données dans Databricks. La question posée est : peut-on propager ces droits dans OneLake (OneSecurity) ? Ou, si ce n’est pas automatique, comment gérer au mieux les autorisations dans cette architecture hybride ?
État des lieux : Sans configuration spéciale, les permissions Unity Catalog ne sont pas connues de OneLake. Ce sont deux plans de contrôle différents :

Unity Catalog gère l’accès aux tables au sein de Databricks (contrôlant qui peut SELECT telle table, voire telle colonne via des Data Masking ou Row Filters).
Fabric OneLake, de son côté, gère l’accès aux éléments Fabric (workspaces, Lakehouses, entrepôts SQL) via les rôles et la sécurité OneLake.

Par défaut, si on miroire une table Unity Catalog dans Fabric, Fabric utilisera un compte de service (un Service Principal configuré pour le miroir, ayant lui-même accès à toutes les tables UC à mirorer) pour interroger Databricks. Ainsi, du point de vue Fabric, tous les utilisateurs ayant accès à l’entrepôt SQL mirroré pourraient potentiellement voir la table, puisque Fabric la récupère via ce compte technique qui a les droits complets. En clair : les ACL Unity Catalog ne “descendent” pas automatiquement jusqu’à l’utilisateur final Fabric.
OneLake Security : Conscient de ce besoin, Microsoft a introduit fin 2025 la possibilité d’appliquer les contrôles de OneLake Security sur les données miroitées de Databricks. OneLake Security permet de définir, au niveau Fabric, des accès fins (table, colonne, voire ligne) sur les items de OneLake. Concrètement, on peut maintenant prendre l’élément “Mirrored Azure Databricks Catalog” dans Fabric et y définir des rôles d’accès OneLake, puis associer des groupes Azure AD à ces rôles avec seulement certaines permissions (par exemple, rôle LecteurVentes qui donne accès en lecture à trois tables du catalogue miroir). Cela complète l’approche : Unity Catalog continue d’appliquer les règles côté Databricks, et OneLake applique des règles équivalentes côté Fabric, assurant une double protection. [blog.fabri...rosoft.com]
Pour que ces deux mondes restent cohérents sans effort titanesque, la meilleure pratique est de s’aligner sur des identités communes :

Utiliser les mêmes groupes Azure AD dans Unity Catalog et dans Fabric. Par exemple, un groupe Analystes_Ventes est utilisé dans Unity Catalog pour donner SELECT sur les tables du domaine Ventes, et le même groupe est ajouté en lecture dans le workspace Fabric du domaine Ventes (ou sur les Lakehouse/entrepôts correspondants).
De cette façon, lorsqu’une personne change d’équipe ou de rôle, elle est ajoutée/supprimée du groupe ad hoc et le changement s’applique dans les deux environnements.

Concrètement, Microsoft propose un petit processus pour “synchroniser” les droits : on peut créer dans Fabric un rôle d’accès OneLake pour les data products du domaine et y ajouter le groupe Azure AD utilisé dans Unity Catalog pour ces data products. Ainsi, ce groupe aura les mêmes accès dans Fabric que dans Databricks. Par exemple, si le groupe NorthWindSalesTeam a accès aux tables du catalogue NorthWind dans Unity Catalog, on miroire le catalogue NorthWind dans Fabric puis on crée un rôle OneLake NorthWind_Readers sur cet item et on y ajoute NorthWindSalesTeam, lui donnant accès aux mêmes tables dans Fabric. Au final, l’équipe NorthWind voit la même chose dans Fabric et Databricks, et si Unity Catalog limitait son accès (disons pas la table “Salaires”), on ne l’aura tout simplement pas mirorée ou on n’ajoutera pas ce groupe sur cette table côté Fabric, préservant la politique. C’est un peu manuel, mais relativement simple à maintenir (beaucoup plus que du double code). [blog.fabri...rosoft.com]
Propagation automatique : Il n’y a pas encore (à ma connaissance début 2026) de mécanisme complètement automatique qui enverrait les ACL Unity Catalog dans Fabric. On reste sur une synchronisation par groupe comme décrit. On peut imaginer qu’à l’avenir, Purview ou une autre couche de gouvernance permettra de définir une fois les règles et de les appliquer aux deux systèmes. Purview, par exemple, commence à introduire des Data Policy centralisées, mais actuellement elles couvrent plutôt Synapse et Storage. Peut-être qu’un jour on pourra dire “groupe X a accès à data product Y” dans Purview et que Purview configurera Unity Catalog et Fabric en conséquence. En attendant, la duplication raisonnée des règles est la voie à suivre.
Gestion des droits recommandée :

Segmenter les accès par environnement : On considère que les outils Databricks (notebooks, etc.) sont utilisés par les équipes data du domaine, tandis que les consommateurs finaux passent par Fabric (Power BI, SQL Endpoint). Donc, par défaut, seuls les membres du domaine ont accès au workspace Databricks du domaine (via Unity Catalog principalement), et ce sont eux qui décident de publier telle ou telle donnée dans Fabric pour d’autres. Ainsi, on limite l’exposition de Databricks – on n’y donne pas un accès large à tout le monde, on passe par Fabric pour cela.
Rôles Azure AD unifiés : Comme déjà mentionné, on crée par exemple un groupe DomainX_DataScientists (accès complet aux données du domaine X, mis comme propriétaire ou au moins lecteur dans Unity Catalog et dans Fabric Domain X), un groupe DomainX_AnalystesMetier (accès seulement aux data products grand public du domaine X, mis en lecteur sur le Lakehouse Fabric du domaine X, et potentiellement n’apparaît même pas dans Unity Catalog s’ils n’utilisent que Fabric). On utilise Azure AD comme couche d’orchestration des identités.
OneLake Security (politiques fines) : Si des restrictions fines sont nécessaires dans Fabric, on les met en place. Ex : la table Customer contient une colonne Email confidentielle que seuls certains peuvent voir. Unity Catalog peut avoir un masque sur Email, mais Fabric ne le saura pas ; on peut alors appliquer dans Fabric soit une Column-Level Security sur le dataset Power BI, soit, plus durablement, une règle OneLake Security sur l’item (disant que tel groupe n’a pas le droit sur la colonne Email). OneLake Security est encore en preview sur les colonnes/lines, mais c’est la voie à suivre pour aligner avec les règles Unity Catalog dynamiques. [blog.fabri...rosoft.com]
Utiliser Purview pour la transparence et la demande d’accès : Purview n’applique pas les accès, mais peut faciliter le workflow. Si un utilisateur d’un autre domaine repère un data product dans Purview et ne peut y accéder (pas membre du groupe autorisé), il peut cliquer “Demander l’accès”. Le propriétaire du data product reçoit alors la demande et peut décider d’accorder l’accès en ajoutant l’utilisateur au groupe AAD adéquat. Ce n’est pas automatique, mais ça rend le processus gouverné et traçable.
Audit multi-couches : Activer l’audit dans Databricks (Unity Catalog enregistre les opérations dans des tables d’audit) et dans Fabric (journal d’accès aux Lakehouse et aux entrepôts SQL). Cela permettra de détecter si, par exemple, un utilisateur tente de consulter une donnée non autorisée. Purview peut consolider une partie de ces informations via ses fonctionnalités d’Insight.

En résumé : Non, il n’y a pas une baguette magique “One Security” qui unifierait d’office Unity Catalog et OneLake. Cependant, en alignant les rôles et groupes entre les deux plates-formes, et avec les nouvelles capacités de OneLake Security, on parvient à une sécurité cohérente sans trop d’effort redondant. Il est impératif de ne pas négliger cet aspect : sans ça, on risque soit de sur-restreindre (ne pas exposer assez de données via Fabric par peur de fuite), soit de sur-ouvrir (exposer via Fabric sans contrôle fin). La solution proposée offre un juste milieu : Databricks reste verrouillé au périmètre du domaine pour le travail interne, Fabric sert d’interface régulée pour le partage, avec la possibilité d’y reproduire les restrictions nécessaires.
6. Autres questions pertinentes et considérations
En se projetant dans cette architecture cible (20 domaines, Databricks + Fabric + Purview), le client pourrait soulever d’autres questions ou cas d’usage. En voici quelques-uns, avec des éléments de réponse :


Environnements de développement et de test : Faut-il des souscriptions séparées pour Dev/Test ?
Idéalement oui, surtout pour isoler les données de production de toute manipulation hasardeuse. On pourrait avoir, pour chaque domaine, une souscription non-prod distincte. Cela ferait potentiellement 40 souscriptions (20 prod + 20 non-prod). Une approche plus pragmatique est de mutualiser les environnements de développement : par exemple, on crée 1 ou 2 souscriptions Sandbox où tous les domaines peuvent faire leurs POC, avec des jeux de données échantillonnés. Mais pour la recette (test des pipelines sur les vraies données), il est préférable d’avoir au moins une séparation des ressources. Une solution fréquente consiste à avoir des Resource Groups “Dev” et “Prod” dans chaque souscription de domaine, avec éventuellement des ACL réseau empêchant l’accès aux données sensibles en Dev. Ou alors deux conteneurs distincts sur le même storage (un datalake-dev et un datalake-prod). Bref, isoler les données métiers critiques tout en évitant de doubler entièrement chaque élément. Dans tous les cas, la production doit être strictement contrôlée (pas de test dessus) et la gestion des coûts surveillée (les environnements de dev étant souvent peu utilisés la nuit, on peut éteindre les clusters etc.).


Coûts additionnels et optimisation : Utiliser à la fois Databricks et Fabric va-t-il coûter plus cher ?
Chaque domaine utilisait déjà Databricks et Power BI. Avec Fabric, Power BI fait partie de Fabric (licence PPU ou Capacitaire), donc il y a un coût Fabric à prendre en compte. Cependant, comme on ne duplique pas les données, on ne paie pas de stockage supplémentaire de données pour Fabric (les fichiers sont stockés une fois, dans les comptes ADLS des domaines). On paiera principalement : les DBU Databricks pour les jobs d’alimentation + les capacités Fabric pour les requêtes et rapports. Si les usages Power BI explosent, il faudra potentiellement une capacité dédiée (ex: Power BI Premium). À l’inverse, on pourrait envisager de réduire un peu la taille des clusters Databricks pour la partie BI, puisque certaines transformations légères peuvent être faites en DAX/Power BI. Globalement, on doit suivre les coûts par composant : Azure Cost Management par souscription pour Databricks & stockage, et le portail M365 admin pour Fabric/Power BI. Purview ajoutera aussi un coût, lié au volume de métadonnées scannées – mais c’est un coût pour la gouvernance qu’on considère justifié.
L’architecture étant modulaire, on pourrait aussi mettre en concurrence les outils sur certains périmètres : par exemple, si un petit domaine a très peu de transformations, on pourrait essayer de le faire entièrement dans Fabric (en utilisant les dataflows ou Spark notebooks de Fabric) et voir si on peut se passer de Databricks pour celui-ci. Cela économiserait les coûts Databricks pour ce petit domaine. Néanmoins, standardiser sur Databricks pour tous les domaines simplifie la mutualisation des compétences et la base de code commune. D’un autre côté, la facturation Fabric pouvant être mutualisée, un domaine peu consommateur “paie” très peu de coût Fabric. Il faudra affiner après quelques mois d’utilisation, domaine par domaine, s’il y a des optimisations possibles (par ex., arrêter un cluster Databricks la nuit pour un domaine qui ne traite qu’en journée, etc.).


Performance et latence de l’accès via OneLake : Consommer via OneLake est-il aussi rapide que d’interroger directement Databricks ?
Dans la majorité des cas, oui, voire plus. Un tableau de bord Power BI qui interroge en DirectLake sur OneLake sera plus rapide qu’un tableau de bord qui interrogerait un cluster Spark en direct (DirectQuery sur Databricks), car on élimine la latence de la couche cluster SQL. De même, un analyste qui fait un SELECT * FROM table sur le SQL Endpoint Fabric verra des performances comparables à un SELECT dans Databricks, car c’est le même fichier parquet qui est lu (peut-être par un moteur différent, mais aux capacités similaires). Il faut bien entendu respecter les bonnes pratiques : partitionner les données par date ou par entité pour éviter de toujours lire l’ensemble du fichier, maintenir à jour les statistiques Delta, etc. Il y a aussi la question du tracking des mises à jour : Delta Lake fournit des ACID transactions et une log, donc si un user commence à lire pendant qu’un job Databricks écrit, tout est cohérent (le user verra l’ancienne version jusqu’à commit). Ce mécanisme continue de fonctionner via OneLake (Fabric voit les tables Delta comme Databricks les voit). On bénéficie aussi du cache Delta (Databricks) et du cache OneLake (Fabric) qui chacun peut conserver temporairement des données chaudes en local pour accélérer les accès répétitifs.


Interopérabilité & évolutivité de l’écosystème : Peut-on intégrer d’autres outils (Data Science, IA) à cette architecture ?
Oui, l’avantage de stocker les données en format ouvert (parquet, Delta) et de les cataloguer dans Purview est qu’on peut brancher n’importe quel outil compatible. Par exemple, un data scientist pourrait très bien utiliser Azure Machine Learning et monter le stockage ADLS du domaine (ou utiliser directement le shortcut OneLake) pour accéder aux données, en parallèle de Databricks. On pourrait aussi imaginer utiliser un moteur SQL dédié (Azure SQL DB, Synapse Serverless) si un besoin particulier le justifiait – même si, avec Fabric, ce n’est sans doute pas nécessaire. L’architecture est suffisamment flexible pour accueillir des changements : exemple, si dans 3 ans Microsoft Fusion (fictif) devenait la plateforme unifiée miracle, on pourrait décider domaine par domaine de migrer du duo Databricks+Fabric vers cette solution, sans remettre en cause le partitionnement par domaines ni la gouvernance centrale.


Questions sur la gouvernance fédérée : Comment s’assurer que chaque domaine respecte bien les standards globaux (qualité, documentation, fréquence de refresh) ?
C’est un volet organisationnel du data mesh : on met en place une gouvernance fédérée. Concrètement, on crée un comité Data avec un représentant de chaque domaine plus l’équipe centrale. Ce comité définit les standards (ex: chaque data product doit avoir un owner et une définition dans Purview, chaque domaine doit rafraîchir ses data products au moins mensuellement, etc.). Purview aide à contrôler cela en listant les data products et leurs métadonnées – on peut par exemple filtrer les jeux de données sans description ou sans owner pour les pointer du doigt. D’autre part, Purview Data Estate Insights fournit une vue d’ensemble de l’usage : on verra si un data product n’est jamais utilisé (peut-être à déprécier) ou si au contraire tout le monde utilise la table X sans qu’elle soit officiellement promue, ce qui peut alerter sur un besoin non couvert. Cette gouvernance doit aussi couvrir les aspects conformité (RGPD, PCI…) – chaque domaine doit étiqueter ses colonnes sensibles, et Purview central pourra appliquer des règles (comme chiffrer ou restreindre l’accès) de manière transversale.


En anticipant ces questions et en y répondant dans la conception, on s’assure que l’architecture ne sera pas seulement techniquement solide, mais aussi adoptée et exploitée efficacement par les équipes métier.
7. Documentation technique et déploiement
Enfin, abordons quelques éléments de documentation technique à produire et un aperçu du déploiement automatisé de l’infrastructure pour ce data mesh.
7.1 Scripts de création de landing zones par domaine
Il est judicieux de préparer des templates d’infrastructure pour déployer l’environnement de chaque domaine de façon cohérente. Par exemple, on peut écrire un script Bicep (Azure Resource Manager) qui, pour un domaine donné, crée le Resource Group, le compte de stockage Data Lake, et le workspace Databricks avec les configurations souhaitées. Voici un extrait simplifié d’un tel template Bicep :
HTMLparam domainName stringparam location string = 'westeurope'// Groupe de ressources principal du domaineresource rg 'Microsoft.Resources/resourceGroups@2021-04-01' = {  name: '${domainName}-rg'  location: location}// Compte de stockage (Data Lake) avec namespace hiérarchique activéresource stg 'Microsoft.Storage/storageAccounts@2022-09-01' = {  name: toLower('${domainName}datalake')  location: location  sku: { name: 'Standard_LRS' }  kind: 'StorageV2'  properties: {    isHnsEnabled: true  // active l'ADLS (Hierarchical Namespace)    allowBlobPublicAccess: false    minimumTlsVersion: 'TLS1_2'  }}// Workspace Azure Databricks (SKU Premium pour Unity Catalog)resource ws 'Microsoft.Databricks/workspaces@2023-05-01' = {  name: '${domainName}-databricks'  location: location  sku: { name: 'premium' }  properties: {    managedResourceGroupId: '/subscriptions/${subscription().subscriptionId}/resourceGroups/${domainName}-databricks-rg'    parameters: {      enableNoPublicIp: { value: true }    // pas d'IP publiques sur les clusters      encryption: { value: 'Enabled' }     // cryptage des disques gérés activé    }  }}// Sorties utilesoutput datalakeName string = stg.nameoutput databricksUrl string = ws.properties.workspaceUrlShow more lines
Explications : Ce code déploie un storage account nommé <domain>datalake avec l’option ADLS Gen2 activée (isHnsEnabled: true), et un workspace Azure Databricks premium. Il crée également le Resource Group dédié. On paramètre enableNoPublicIp à true pour renforcer la sécurité réseau (les clusters n’auront pas d’IP publique) et on précise le resource group managé de Databricks (il contiendra les VMs du service Databricks) pour le nommer proprement. En sortie, on fournit l’URL du workspace Databricks, qui servira ensuite pour configurer l’accès (on devra par exemple l’utiliser pour créer le lien de mirroring dans Fabric, ou pour que Purview sache où se connecter).
Avec un tel template, on peut déployer en boucle pour chaque domaine en passant un domainName différent (Marketing, Finance, etc.), ce qui créera l’infra de base de tous les domaines de manière standardisée.
On pourra enrichir le script pour inclure d’autres composants si nécessaire (par ex, créer un Key Vault pour stocker les secrets du domaine, un Event Hub pour ingestion en temps réel, etc., en fonction des besoins communs ou spécifiques).
7.2 Automatisation de la configuration
Après le déploiement de l’infrastructure, il reste des tâches de configuration logicielle à automatiser autant que possible :

Initialisation Unity Catalog : Via des scripts Databricks (que l’on peut déclencher avec le Databricks CLI ou l’API), on peut créer le metastore Unity Catalog du domaine, définir les bases (catalog et schémas bronze/silver/gold), lier le compte de stockage ADLS comme external location par défaut du metastore (afin que toutes les tables Unity Catalog écrivent sur le bon storage), et créer les premiers rôles/grants. Ceci afin que dès la première utilisation, les ingénieurs du domaine puissent enregistrer leurs tables Delta dans Unity Catalog proprement.
Setup Purview : Automatiser l’enregistrement des sources de données dans Purview pour chaque domaine. On peut utiliser l’API REST Purview pour créer une collection par domaine, puis y enregistrer deux sources : (1) le compte ADLS du domaine (pour scanner les fichiers/dossiers et éventuellement les data lake zones qui ne seraient pas tables), (2) la source Unity Catalog du domaine (Purview propose un connecteur Unity Catalog qui se connecte au workspace Databricks – en pratique via le SQL Warehouse Databricks associé – et extrait toutes les tables avec leur lineage). En scriptant cela, on évite de le faire 20 fois manuellement. Purview pourra ensuite scanner à intervalles réguliers (ex: tous les jours) pour mettre à jour le catalogue. [learn.microsoft.com]
Provisionnement Fabric : Si on souhaite pré-créer les espaces Fabric pour chaque domaine (workspaces, Lakehouse), on peut le faire via les API Power BI REST. Par exemple, un script PowerShell peut créer un workspace Fabric “DomaineX”, y ajouter un Lakehouse nommé “DomaineX_Lakehouse”. La création du raccourci OneLake peut être automatisée via l’API Fabric (il y a une API REST pour créer des shortcuts également, ou on peut utiliser un notebook Fabric piloté). Cependant, comme Fabric évolue rapidement, il peut être acceptable de faire certaines configurations via l’interface pour l’instant, surtout que c’est ponctuel par domaine. L’important est d’avoir un guide d’onboarding bien défini : “comment passer un data product de Databricks à Fabric” pour chaque équipe domaine.

7.3 Schéma global de l’architecture cible
Intégrons maintenant tous les composants dans un schéma d’architecture global pour avoir une vue d’ensemble de la solution :
Parse error on line 10:
...c [Microsoft Fabric (OneLake)]      ALH
-----------------------^
Expecting 'SQE', 'DOUBLECIRCLEEND', 'PE', '-)', 'STADIUMEND', 'SUBROUTINEEND', 'PIPE', 'CYLINDEREND', 'DIAMOND_STOP', 'TAGEND', 'TRAPEND', 'INVTRAPEND', 'UNICODE_TEXT', 'TEXT', 'TAGSTART', got 'PS'Show more lines
Description du schéma : À gauche, on a deux exemples de domaines (A et B), chacun avec son environnement Databricks (cercle bleu) et son Data Lake (cylindre bleu). Les tables sont cataloguées dans Unity Catalog (losange violet) propre à chaque domaine. Au centre, OneLake (Fabric) agrège la vue : chaque domaine a un Lakehouse (carré orange) qui référence son storage (flèches “Shortcut”) et un Endpoint SQL mirror (cylindre orange) qui référence son Unity Catalog (flèches “Mirror”). En haut, Purview (bloc gris) scanne aussi bien les sources Azure (Unity Catalog, stockage) de chaque domaine que OneLake, construisant le catalogue global. À droite, les consommateurs peuvent être de différents types : un utilisateur Power BI (icône BI) accède aux données via le Lakehouse ou le Endpoint SQL dans Fabric ; un data scientist (icône DS) peut soit passer par Fabric, soit se connecter directement au workspace Databricks du domaine s’il y est autorisé (par exemple pour des besoins très spécifiques) ; une application métier (icône APP) peut consommer un data product via une API exposée sur Fabric (par exemple, un service web qui requête l’entrepôt SQL Fabric du domaine B pour obtenir une réponse).
Ce schéma illustre le double rôle de Purview et Fabric : Purview pour la visibilité globale (il sait par exemple que la table Clients du domaine A alimente une vue du domaine B, etc.), et Fabric OneLake pour l’accessibilité globale (il sert de hub d’accès aux données sans toutefois les stocker lui-même).
7.4 Piloter et documenter le déploiement
Pour maintenir cette architecture, quelques documents et outils vont accompagner les scripts :

Un runbook de déploiement décrivant comment ajouter un nouveau domaine : liste des étapes (créer la souscription, lancer le template IaC, configurer Purview, configurer Fabric, etc.). Idéalement, beaucoup de ces étapes seront automatisées, mais ce document permet de garder une vue séquentielle et de répartir les tâches (certaines faites par l’IT, d’autres par l’équipe data du domaine).
Une documentation utilisateur pour les équipes domaine : comment utiliser Unity Catalog, comment publier un data product (via Fabric, via Purview). Par exemple, un tutoriel “J’ai une nouvelle table dans Databricks, comment la rendre disponible aux autres via Fabric ?” avec captures d’écran.
Des tableaux de bord de suivi (Power BI) pour la gouvernance : par ex, un rapport Cost Management multi-souscriptions ; un rapport Purview listant les data products par domaine et leur état de complétude (description présente ? classification faite ?).
Concernant les schémas d’architecture, le présent document en fournit deux en Mermaid (domaine et global). Il peut être utile de les reproduire dans un format plus visuel (Visio ou Lucidchart) pour des présentations aux parties prenantes non techniques. Ils pourront aussi servir de base pour un schéma plus complet incluant, par exemple, les flux de données inter-domaines (ici on a surtout représenté l’état statique).


En conclusion, l’architecture proposée répond point par point aux interrogations initiales :

Découpage par souscriptions : C’est le choix recommandé pour isoler les 20 entités, avec un focus showback par domaine facile. On a couvert les limites (complexité, migration) et comment les adresser.
Migration des ressources : Possible sans interruption pour le stockage (Azure Resource Move), nécessite recréation pour Databricks (outil de migration fourni) – exemples de scripts fournis. [learn.microsoft.com] [learn.microsoft.com], [learn.microsoft.com]
Organisation d’un Data Domain : On a décrit la composition (ADLS, Databricks, Unity Catalog, data products) et montré comment l’attacher à OneLake (raccourci, mirror). Schéma Mermaid à l’appui.
Intégration Databricks–OneLake : On a expliqué les mécanismes (shortcuts ABFS, open APIs Unity Catalog) permettant une exposition sans copie, avec un schéma d’architecture détaillé. [databricks.com]
Gestion des droits : Pas de propagation automatique, mais une stratégie pour aligner les accès via AAD et OneLake Security. On a donné les bonnes pratiques pour maintenir la sécurité cohérente sur les deux plateformes. [blog.fabri...rosoft.com]
Questions supplémentaires : On a abordé les sujets de dév/test, de coût, de performance, de gouvernance, afin de rassurer sur la viabilité opérationnelle de la solution. Un tableau comparatif a été fourni pour le choix souscription vs resource group.

Cette architecture, articulée autour du concept de domaine (domain-driven) et épaulée par des outils de fédération (OneLake, Purview), permet d’allier décentralisation (chaque entité gère son infrastructure, ses données) et centralisation là où c’est nécessaire (catalogue global, point d’accès unifié, politiques transverses de sécurité). Le résultat attenduo est un data mesh fonctionnel où les données circulent de manière gouvernée et efficiente, accélérant la production de valeur analytique pour l’ensemble de l’organisation. Toutes les pièces sont en place pour que le client, fort de cette documentation, puisse entreprendre la mise en œuvre en minimisant les risques et en maximisant les bénéfices.
